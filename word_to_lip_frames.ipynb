{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "sFoKYIslx9PA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9323b26f-3864-4f98-b484-5e96bf094dc4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import nltk\n",
        "from nltk.corpus import cmudict\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "# Download CMUdict if not already\n",
        "nltk.download('cmudict')\n",
        "cmu_dict = cmudict.dict()\n",
        "\n",
        "# Phoneme to viseme class mapping\n",
        "phoneme_to_mouth_shape = {\n",
        "    # Closed lips\n",
        "    \"b\": \"01_Closed_Lips\",\n",
        "    \"p\": \"01_Closed_Lips\",\n",
        "    \"m\": \"01_Closed_Lips\",\n",
        "\n",
        "    # Teeth touching\n",
        "    \"f\": \"02_Teeth_Touching\",\n",
        "    \"v\": \"02_Teeth_Touching\",\n",
        "    \"th\": \"02_Teeth_Touching\",\n",
        "    \"dh\": \"02_Teeth_Touching\",\n",
        "\n",
        "    # Open mouth vowels\n",
        "    \"aa\": \"03_Open_Mouth\",\n",
        "    \"ae\": \"03_Open_Mouth\",\n",
        "    \"ah\": \"03_Open_Mouth\",\n",
        "    \"eh\": \"03_Open_Mouth\",\n",
        "    \"ih\": \"03_Open_Mouth\",\n",
        "    \"iy\": \"03_Open_Mouth\",\n",
        "    \"er\": \"03_Open_Mouth\",\n",
        "    \"ey\": \"03_Open_Mouth\",\n",
        "    \"g\": \"03_Open_Mouth\",\n",
        "    \"k\": \"03_Open_Mouth\",\n",
        "    \"uh\": \"03_Open_Mouth\",\n",
        "    \"uw\": \"03_Open_Mouth\",\n",
        "    \"hh\": \"03_Open_Mouth\",\n",
        "\n",
        "    # Rounded lips vowels and glides\n",
        "    \"aw\": \"04_Rounded_Lips\",\n",
        "    \"ow\": \"04_Rounded_Lips\",\n",
        "    \"oy\": \"04_Rounded_Lips\",\n",
        "    \"w\": \"04_Rounded_Lips\",\n",
        "\n",
        "    # Tongue behind teeth\n",
        "    \"t\": \"05_Tongue_Behind_Teeth\",\n",
        "    \"d\": \"05_Tongue_Behind_Teeth\",\n",
        "    \"n\": \"05_Tongue_Behind_Teeth\",\n",
        "    \"s\": \"05_Tongue_Behind_Teeth\",\n",
        "    \"z\": \"05_Tongue_Behind_Teeth\",\n",
        "\n",
        "    # Retroflex sounds\n",
        "    \"r\": \"06_Retroflex\",\n",
        "    \"jh\": \"06_Retroflex\",\n",
        "\n",
        "    # Fricatives and sibilants\n",
        "    \"sh\": \"07_Fricative_Sibilant\",\n",
        "    \"zh\": \"07_Fricative_Sibilant\",\n",
        "    \"ch\": \"07_Fricative_Sibilant\",\n",
        "\n",
        "    # Nasal (back)\n",
        "    \"ng\": \"08_Nasal\",\n",
        "\n",
        "    # Lateral\n",
        "    \"l\": \"09_Lateral\",\n",
        "\n",
        "    # Semi-vowels (glides)\n",
        "    \"y\": \"10_Semi_Vowel\",\n",
        "\n",
        "    # Diphthongs and others (some overlapping)\n",
        "    \"ay\": \"03_Open_Mouth\",\n",
        "}\n",
        "\n",
        "# --- Helpers ---\n",
        "\n",
        "def get_phonemes_from_cmudict(word):\n",
        "    word = word.lower()\n",
        "    if word not in cmu_dict:\n",
        "        raise ValueError(f\"No phonemes found for word '{word}'\")\n",
        "    phonemes = cmu_dict[word][0]\n",
        "    return [p.lower().strip(\"0123456789\") for p in phonemes]\n",
        "\n",
        "def load_gan_model(viseme_class_path, epoch=100):\n",
        "    model_path = f\"{viseme_class_path}/generator_epoch_{epoch}.model.keras\"\n",
        "    return tf.keras.models.load_model(model_path)\n",
        "\n",
        "def generate_lip_frames(generator, latent_dim=100):\n",
        "    z = np.random.normal(0, 1, (1, latent_dim))\n",
        "    return generator.predict(z)\n",
        "\n",
        "def save_as_png(image_array, save_path):\n",
        "    image_array = np.clip(image_array, 0, 1)\n",
        "    image_array = (image_array * 255).astype(np.uint8)\n",
        "    img = Image.fromarray(image_array)\n",
        "    img.save(save_path)\n",
        "\n",
        "def create_gif_from_frames(folder_path, output_path=\"output.gif\", duration=500):\n",
        "    frame_files = sorted([f for f in os.listdir(folder_path) if f.endswith(\".png\")])\n",
        "    frames = [Image.open(os.path.join(folder_path, f)) for f in frame_files]\n",
        "\n",
        "    if frames:\n",
        "        frames[0].save(\n",
        "            output_path,\n",
        "            format=\"GIF\",\n",
        "            save_all=True,\n",
        "            append_images=frames[1:],\n",
        "            duration=duration,\n",
        "            loop=0\n",
        "        )\n",
        "        print(f\"✅ GIF saved to: {output_path}\")\n",
        "    else:\n",
        "        print(\"⚠️ No PNG files found to create GIF.\")\n",
        "\n",
        "def create_mp4_from_frames(folder_path, output_path=\"output.mp4\", fps=1):\n",
        "    frame_files = sorted([f for f in os.listdir(folder_path) if f.endswith(\".png\")])\n",
        "    if not frame_files:\n",
        "        print(\"⚠️ No PNG files found to create MP4.\")\n",
        "        return\n",
        "\n",
        "    first_frame = cv2.imread(os.path.join(folder_path, frame_files[0]))\n",
        "    height, width, _ = first_frame.shape\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    video = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    for file_name in frame_files:\n",
        "        frame = cv2.imread(os.path.join(folder_path, file_name))\n",
        "        video.write(frame)\n",
        "\n",
        "    video.release()\n",
        "    print(f\"✅ MP4 video saved to: {output_path}\")\n",
        "\n",
        "# --- Phoneme Duration Prediction ---\n",
        "\n",
        "def predict_phoneme_durations(phonemes, base_duration=0.1):\n",
        "    \"\"\"\n",
        "    Predict durations for each phoneme.\n",
        "    This is a simple rule-based predictor assigning a base duration to each phoneme.\n",
        "    \"\"\"\n",
        "    durations = []\n",
        "    for phoneme in phonemes:\n",
        "        # Assign longer duration to vowels\n",
        "        if phoneme in ['aa', 'ae', 'ah', 'eh', 'ih', 'iy', 'er', 'ey', 'uh', 'uw', 'aw', 'ow', 'oy', 'ay']:\n",
        "            durations.append(base_duration * 1.5)\n",
        "        else:\n",
        "            durations.append(base_duration)\n",
        "    return durations\n",
        "\n",
        "# --- Main generation logic ---\n",
        "\n",
        "def generate_from_word(word, base_model_dir, save_dir, fps=25):\n",
        "    phonemes = get_phonemes_from_cmudict(word)\n",
        "    print(f\"Phonemes: {phonemes}\")\n",
        "\n",
        "    durations = predict_phoneme_durations(phonemes)\n",
        "    print(f\"Predicted durations: {durations}\")\n",
        "\n",
        "    output_path = os.path.join(save_dir, word)\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "    frame_idx = 0\n",
        "\n",
        "    for phoneme, duration in zip(phonemes, durations):\n",
        "        viseme_class = phoneme_to_mouth_shape.get(phoneme)\n",
        "        if not viseme_class:\n",
        "            print(f\"Skipping unknown phoneme: {phoneme}\")\n",
        "            continue\n",
        "\n",
        "        generator_path = os.path.join(base_model_dir, viseme_class)\n",
        "        if not os.path.exists(generator_path):\n",
        "            print(f\"GAN model for {viseme_class} not found, skipping.\")\n",
        "            continue\n",
        "\n",
        "        generator = load_gan_model(generator_path)\n",
        "\n",
        "        # Calculate number of frames for this phoneme based on duration and fps\n",
        "        num_frames = max(1, int(duration * fps))\n",
        "\n",
        "        for _ in range(num_frames):\n",
        "            generated_clip = generate_lip_frames(generator)\n",
        "\n",
        "            if generated_clip.ndim == 5:\n",
        "                frame = generated_clip[0, 0]\n",
        "            elif generated_clip.ndim == 4:\n",
        "                frame = generated_clip[0]\n",
        "            else:\n",
        "                frame = generated_clip\n",
        "\n",
        "            save_path = os.path.join(output_path, f\"frame_{frame_idx:03d}.png\")\n",
        "            save_as_png(frame, save_path)\n",
        "            frame_idx += 1\n",
        "\n",
        "    print(f\"✅ PNG frames saved to: {output_path}\")\n",
        "\n",
        "    # Create GIF and MP4\n",
        "    gif_path = os.path.join(save_dir, f\"{word}.gif\")\n",
        "    mp4_path = os.path.join(save_dir, f\"{word}.mp4\")\n",
        "    create_gif_from_frames(output_path, gif_path, duration=int(1000 / fps))\n",
        "    create_mp4_from_frames(output_path, mp4_path, fps=fps)\n",
        "\n",
        "    return output_path\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc-M1OcR4zn3",
        "outputId": "38d61cd5-9374-4a22-b256-e8819aa98069"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/cmudict.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Run ---\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    word = input(\"Enter a word: \").strip()\n",
        "    base_model_dir = \"/content/drive/MyDrive/All_outputs/gans_allfolders\"\n",
        "    save_dir = \"/content/drive/MyDrive/All_outputs/mergeGANS\"\n",
        "    generate_from_word(word, base_model_dir, save_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6KQNkMSbMXW",
        "outputId": "84194be2-61d7-4639-c2b9-a71d7d3d534a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a word: smile\n",
            "Phonemes: ['s', 'm', 'ay', 'l']\n",
            "Predicted durations: [0.1, 0.1, 0.15000000000000002, 0.1]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "✅ PNG frames saved to: /content/drive/MyDrive/All_outputs/mergeGANS/smile\n",
            "✅ GIF saved to: /content/drive/MyDrive/All_outputs/mergeGANS/smile.gif\n",
            "✅ MP4 video saved to: /content/drive/MyDrive/All_outputs/mergeGANS/smile.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FRONTEND"
      ],
      "metadata": {
        "id": "nFJyQtu0R4OM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio --quiet\n"
      ],
      "metadata": {
        "id": "U9QyeU_hR6jk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cea328cf-08bb-4b00-eba2-ae8cca242f1d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.1/54.1 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.9/322.9 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m115.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import os  # Just to be sure it's included\n",
        "\n",
        "def frontend_generate(word):\n",
        "    base_model_dir = \"/content/drive/MyDrive/All_outputs/gans_allfolders\"\n",
        "    save_dir = \"/content/drive/MyDrive/All_outputs/mergeGANS\"\n",
        "\n",
        "    try:\n",
        "        output_path = generate_from_word(word, base_model_dir, save_dir)\n",
        "\n",
        "        # Get all frame file paths sorted by filename\n",
        "        frame_paths = sorted([\n",
        "            os.path.join(output_path, fname)\n",
        "            for fname in os.listdir(output_path)\n",
        "            if fname.endswith(\".png\")\n",
        "        ])\n",
        "\n",
        "        return frame_paths\n",
        "    except Exception as e:\n",
        "        # Return an empty list and optionally print the error\n",
        "        print(f\"❌ Error: {e}\")\n",
        "        return []\n",
        "\n"
      ],
      "metadata": {
        "id": "WJBvPPDiSBrz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "interface = gr.Interface(\n",
        "    fn=frontend_generate,\n",
        "    inputs=gr.Textbox(label=\"Enter a word\"),\n",
        "    outputs=gr.Gallery(label=\"Generated Lip Frames\", columns=5, height=\"auto\"),\n",
        "    title=\"Viseme GAN Generator\",\n",
        "    description=\"Enter a word to generate lip frame sequence using viseme-specific GANs.\"\n",
        ")"
      ],
      "metadata": {
        "id": "S0ahg-HbSC9q"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interface.launch(share=True)\n"
      ],
      "metadata": {
        "id": "jAffmuw-Y7_M",
        "outputId": "27a18d10-79d9-462e-efbf-9016f8feab2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://7b26d47e822ecffdb6.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://7b26d47e822ecffdb6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "_________________________________________"
      ],
      "metadata": {
        "id": "gylsxYB7Wob1"
      }
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "sFoKYIslx9PA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf6c4c63-504b-47fc-ea48-192a97d27ca1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import nltk\n",
        "from nltk.corpus import cmudict\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "# Download CMUdict if not already\n",
        "nltk.download('cmudict')\n",
        "cmu_dict = cmudict.dict()\n",
        "\n",
        "# Phoneme to viseme class mapping\n",
        "phoneme_to_mouth_shape = {\n",
        "    # Closed lips\n",
        "    \"b\": \"01_Closed_Lips\",\n",
        "    \"p\": \"01_Closed_Lips\",\n",
        "    \"m\": \"01_Closed_Lips\",\n",
        "\n",
        "    # Teeth touching\n",
        "    \"f\": \"02_Teeth_Touching\",\n",
        "    \"v\": \"02_Teeth_Touching\",\n",
        "    \"th\": \"02_Teeth_Touching\",\n",
        "    \"dh\": \"02_Teeth_Touching\",\n",
        "\n",
        "    # Open mouth vowels\n",
        "    \"aa\": \"03_Open_Mouth\",\n",
        "    \"ae\": \"03_Open_Mouth\",\n",
        "    \"ah\": \"03_Open_Mouth\",\n",
        "    \"eh\": \"03_Open_Mouth\",\n",
        "    \"ih\": \"03_Open_Mouth\",\n",
        "    \"iy\": \"03_Open_Mouth\",\n",
        "    \"er\": \"03_Open_Mouth\",\n",
        "    \"ey\": \"03_Open_Mouth\",\n",
        "    \"g\": \"03_Open_Mouth\",\n",
        "    \"k\": \"03_Open_Mouth\",\n",
        "    \"uh\": \"03_Open_Mouth\",\n",
        "    \"uw\": \"03_Open_Mouth\",\n",
        "    \"hh\": \"03_Open_Mouth\",\n",
        "\n",
        "    # Rounded lips vowels and glides\n",
        "    \"aw\": \"04_Rounded_Lips\",\n",
        "    \"ow\": \"04_Rounded_Lips\",\n",
        "    \"oy\": \"04_Rounded_Lips\",\n",
        "    \"w\": \"04_Rounded_Lips\",\n",
        "\n",
        "    # Tongue behind teeth\n",
        "    \"t\": \"05_Tongue_Behind_Teeth\",\n",
        "    \"d\": \"05_Tongue_Behind_Teeth\",\n",
        "    \"n\": \"05_Tongue_Behind_Teeth\",\n",
        "    \"s\": \"05_Tongue_Behind_Teeth\",\n",
        "    \"z\": \"05_Tongue_Behind_Teeth\",\n",
        "\n",
        "    # Retroflex sounds\n",
        "    \"r\": \"06_Retroflex\",\n",
        "    \"jh\": \"06_Retroflex\",\n",
        "\n",
        "    # Fricatives and sibilants\n",
        "    \"sh\": \"07_Fricative_Sibilant\",\n",
        "    \"zh\": \"07_Fricative_Sibilant\",\n",
        "    \"ch\": \"07_Fricative_Sibilant\",\n",
        "\n",
        "    # Nasal (back)\n",
        "    \"ng\": \"08_Nasal\",\n",
        "\n",
        "    # Lateral\n",
        "    \"l\": \"09_Lateral\",\n",
        "\n",
        "    # Semi-vowels (glides)\n",
        "    \"y\": \"10_Semi_Vowel\",\n",
        "\n",
        "    # Diphthongs and others (some overlapping)\n",
        "    \"ay\": \"03_Open_Mouth\",\n",
        "}\n",
        "\n",
        "# --- Helpers ---\n",
        "\n",
        "def get_phonemes_from_cmudict(word):\n",
        "    word = word.lower()\n",
        "    if word not in cmu_dict:\n",
        "        raise ValueError(f\"No phonemes found for word '{word}'\")\n",
        "    phonemes = cmu_dict[word][0]\n",
        "    return [p.lower().strip(\"0123456789\") for p in phonemes]\n",
        "\n",
        "def load_gan_model(viseme_class_path, epoch=100):\n",
        "    model_path = f\"{viseme_class_path}/generator_epoch_{epoch}.model.keras\"\n",
        "    return tf.keras.models.load_model(model_path)\n",
        "\n",
        "def generate_lip_frames(generator, latent_dim=100):\n",
        "    z = np.random.normal(0, 1, (1, latent_dim))\n",
        "    return generator.predict(z)\n",
        "\n",
        "def save_as_png(image_array, save_path):\n",
        "    image_array = np.clip(image_array, 0, 1)\n",
        "    image_array = (image_array * 255).astype(np.uint8)\n",
        "    img = Image.fromarray(image_array)\n",
        "    img.save(save_path)\n",
        "\n",
        "def create_gif_from_frames(folder_path, output_path=\"output.gif\", duration=500):\n",
        "    frame_files = sorted([f for f in os.listdir(folder_path) if f.endswith(\".png\")])\n",
        "    frames = [Image.open(os.path.join(folder_path, f)) for f in frame_files]\n",
        "\n",
        "    if frames:\n",
        "        frames[0].save(\n",
        "            output_path,\n",
        "            format=\"GIF\",\n",
        "            save_all=True,\n",
        "            append_images=frames[1:],\n",
        "            duration=duration,\n",
        "            loop=0\n",
        "        )\n",
        "        print(f\"✅ GIF saved to: {output_path}\")\n",
        "    else:\n",
        "        print(\"⚠️ No PNG files found to create GIF.\")\n",
        "\n",
        "def create_mp4_from_frames(folder_path, output_path=\"output.mp4\", fps=1):\n",
        "    frame_files = sorted([f for f in os.listdir(folder_path) if f.endswith(\".png\")])\n",
        "    if not frame_files:\n",
        "        print(\"⚠️ No PNG files found to create MP4.\")\n",
        "        return\n",
        "\n",
        "    first_frame = cv2.imread(os.path.join(folder_path, frame_files[0]))\n",
        "    height, width, _ = first_frame.shape\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    video = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    for file_name in frame_files:\n",
        "        frame = cv2.imread(os.path.join(folder_path, file_name))\n",
        "        video.write(frame)\n",
        "\n",
        "    video.release()\n",
        "    print(f\"✅ MP4 video saved to: {output_path}\")\n",
        "\n",
        "# --- Phoneme Duration Prediction ---\n",
        "\n",
        "def predict_phoneme_durations(phonemes, base_duration=0.1):\n",
        "    \"\"\"\n",
        "    Predict durations for each phoneme.\n",
        "    This is a simple rule-based predictor assigning a base duration to each phoneme.\n",
        "    \"\"\"\n",
        "    durations = []\n",
        "    for phoneme in phonemes:\n",
        "        # Assign longer duration to vowels\n",
        "        if phoneme in ['aa', 'ae', 'ah', 'eh', 'ih', 'iy', 'er', 'ey', 'uh', 'uw', 'aw', 'ow', 'oy', 'ay']:\n",
        "            durations.append(base_duration * 1.5)\n",
        "        else:\n",
        "            durations.append(base_duration)\n",
        "    return durations\n",
        "\n",
        "# --- Main generation logic ---\n",
        "\n",
        "def generate_from_word(word, base_model_dir, save_dir, fps=25):\n",
        "    phonemes = get_phonemes_from_cmudict(word)\n",
        "    print(f\"Phonemes: {phonemes}\")\n",
        "\n",
        "    durations = predict_phoneme_durations(phonemes)\n",
        "    print(f\"Predicted durations: {durations}\")\n",
        "\n",
        "    output_path = os.path.join(save_dir, word)\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "    frame_idx = 0\n",
        "\n",
        "    for phoneme, duration in zip(phonemes, durations):\n",
        "        viseme_class = phoneme_to_mouth_shape.get(phoneme)\n",
        "        if not viseme_class:\n",
        "            print(f\"Skipping unknown phoneme: {phoneme}\")\n",
        "            continue\n",
        "\n",
        "        generator_path = os.path.join(base_model_dir, viseme_class)\n",
        "        if not os.path.exists(generator_path):\n",
        "            print(f\"GAN model for {viseme_class} not found, skipping.\")\n",
        "            continue\n",
        "\n",
        "        generator = load_gan_model(generator_path)\n",
        "\n",
        "        # Calculate number of frames for this phoneme based on duration and fps\n",
        "        num_frames = max(1, int(duration * fps))\n",
        "\n",
        "        for _ in range(num_frames):\n",
        "            generated_clip = generate_lip_frames(generator)\n",
        "\n",
        "            if generated_clip.ndim == 5:\n",
        "                frame = generated_clip[0, 0]\n",
        "            elif generated_clip.ndim == 4:\n",
        "                frame = generated_clip[0]\n",
        "            else:\n",
        "                frame = generated_clip\n",
        "\n",
        "            save_path = os.path.join(output_path, f\"frame_{frame_idx:03d}.png\")\n",
        "            save_as_png(frame, save_path)\n",
        "            frame_idx += 1\n",
        "\n",
        "    print(f\"✅ PNG frames saved to: {output_path}\")\n",
        "\n",
        "    # Create GIF and MP4\n",
        "    gif_path = os.path.join(save_dir, f\"{word}.gif\")\n",
        "    mp4_path = os.path.join(save_dir, f\"{word}.mp4\")\n",
        "    create_gif_from_frames(output_path, gif_path, duration=int(1000 / fps))\n",
        "    create_mp4_from_frames(output_path, mp4_path, fps=fps)\n",
        "\n",
        "    return output_path\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc-M1OcR4zn3",
        "outputId": "189f7bd5-c075-4df7-e06f-bfd1a10a7743"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]   Package cmudict is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Run ---\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    word = input(\"Enter a word: \").strip()\n",
        "    base_model_dir = \"/content/drive/MyDrive/All_outputs/gans_allfolders\"\n",
        "    save_dir = \"/content/drive/MyDrive/All_outputs/mergeGANS\"\n",
        "    generate_from_word(word, base_model_dir, save_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6KQNkMSbMXW",
        "outputId": "688f251c-0ae8-4938-c500-c5050985e272"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a word: read\n",
            "Phonemes: ['r', 'eh', 'd']\n",
            "Predicted durations: [0.1, 0.15000000000000002, 0.1]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "✅ PNG frames saved to: /content/drive/MyDrive/All_outputs/mergeGANS/read\n",
            "✅ GIF saved to: /content/drive/MyDrive/All_outputs/mergeGANS/read.gif\n",
            "✅ MP4 video saved to: /content/drive/MyDrive/All_outputs/mergeGANS/read.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FRONTEND"
      ],
      "metadata": {
        "id": "nFJyQtu0R4OM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio --quiet\n"
      ],
      "metadata": {
        "id": "U9QyeU_hR6jk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import os  # Just to be sure it's included\n",
        "\n",
        "def frontend_generate(word):\n",
        "    base_model_dir = \"/content/drive/MyDrive/All_outputs/gans_allfolders\"\n",
        "    save_dir = \"/content/drive/MyDrive/All_outputs/mergeGANS\"\n",
        "\n",
        "    try:\n",
        "        output_path = generate_from_word(word, base_model_dir, save_dir)\n",
        "\n",
        "        # Get all frame file paths sorted by filename\n",
        "        frame_paths = sorted([\n",
        "            os.path.join(output_path, fname)\n",
        "            for fname in os.listdir(output_path)\n",
        "            if fname.endswith(\".png\")\n",
        "        ])\n",
        "\n",
        "        return frame_paths\n",
        "    except Exception as e:\n",
        "        # Return an empty list and optionally print the error\n",
        "        print(f\"❌ Error: {e}\")\n",
        "        return []\n",
        "\n"
      ],
      "metadata": {
        "id": "WJBvPPDiSBrz"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "interface = gr.Interface(\n",
        "    fn=frontend_generate,\n",
        "    inputs=gr.Textbox(label=\"Enter a word\"),\n",
        "    outputs=gr.Gallery(label=\"Generated Lip Frames\", columns=5, height=\"auto\"),\n",
        "    title=\"Viseme GAN Generator\",\n",
        "    description=\"Enter a word to generate lip frame sequence using viseme-specific GANs.\"\n",
        ")"
      ],
      "metadata": {
        "id": "S0ahg-HbSC9q"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interface.launch(share=True)\n"
      ],
      "metadata": {
        "id": "jAffmuw-Y7_M",
        "outputId": "6bc34fc9-1910-4edd-8afb-517d2f3c1378",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://e5d633435a36bbcab5.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e5d633435a36bbcab5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "_________________________________________"
      ],
      "metadata": {
        "id": "gylsxYB7Wob1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#WITH INPUT IMAGE"
      ],
      "metadata": {
        "id": "paXxd8qE_gzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#install media pipe\n",
        "!pip install mediapipe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGBmw6WO_gBq",
        "outputId": "cc089e3f-fa3e-4364-8237-b8521258d135",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.10.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Collecting protobuf<5,>=4.25.3 (from mediapipe)\n",
            "  Downloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (1.15.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
            "Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl (35.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: protobuf, sounddevice, mediapipe\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.7 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.7 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed mediapipe-0.10.21 protobuf-4.25.7 sounddevice-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import nltk\n",
        "from nltk.corpus import cmudict\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "# Download CMUdict if not already\n",
        "nltk.download('cmudict')\n",
        "cmu_dict = cmudict.dict()\n",
        "\n",
        "# Phoneme to viseme class mapping\n",
        "phoneme_to_mouth_shape = {\n",
        "    # Closed lips\n",
        "    \"b\": \"01_Closed_Lips\",\n",
        "    \"p\": \"01_Closed_Lips\",\n",
        "    \"m\": \"01_Closed_Lips\",\n",
        "\n",
        "    # Teeth touching\n",
        "    \"f\": \"02_Teeth_Touching\",\n",
        "    \"v\": \"02_Teeth_Touching\",\n",
        "    \"th\": \"02_Teeth_Touching\",\n",
        "    \"dh\": \"02_Teeth_Touching\",\n",
        "\n",
        "    # Open mouth vowels\n",
        "    \"aa\": \"03_Open_Mouth\",\n",
        "    \"ae\": \"03_Open_Mouth\",\n",
        "    \"ah\": \"03_Open_Mouth\",\n",
        "    \"eh\": \"03_Open_Mouth\",\n",
        "    \"ih\": \"03_Open_Mouth\",\n",
        "    \"iy\": \"03_Open_Mouth\",\n",
        "    \"er\": \"03_Open_Mouth\",\n",
        "    \"ey\": \"03_Open_Mouth\",\n",
        "    \"g\": \"03_Open_Mouth\",\n",
        "    \"k\": \"03_Open_Mouth\",\n",
        "    \"uh\": \"03_Open_Mouth\",\n",
        "    \"uw\": \"03_Open_Mouth\",\n",
        "    \"hh\": \"03_Open_Mouth\",\n",
        "\n",
        "    # Rounded lips vowels and glides\n",
        "    \"aw\": \"04_Rounded_Lips\",\n",
        "    \"ow\": \"04_Rounded_Lips\",\n",
        "    \"oy\": \"04_Rounded_Lips\",\n",
        "    \"w\": \"04_Rounded_Lips\",\n",
        "\n",
        "    # Tongue behind teeth\n",
        "    \"t\": \"05_Tongue_Behind_Teeth\",\n",
        "    \"d\": \"05_Tongue_Behind_Teeth\",\n",
        "    \"n\": \"05_Tongue_Behind_Teeth\",\n",
        "    \"s\": \"05_Tongue_Behind_Teeth\",\n",
        "    \"z\": \"05_Tongue_Behind_Teeth\",\n",
        "\n",
        "    # Retroflex sounds\n",
        "    \"r\": \"06_Retroflex\",\n",
        "    \"jh\": \"06_Retroflex\",\n",
        "\n",
        "    # Fricatives and sibilants\n",
        "    \"sh\": \"07_Fricative_Sibilant\",\n",
        "    \"zh\": \"07_Fricative_Sibilant\",\n",
        "    \"ch\": \"07_Fricative_Sibilant\",\n",
        "\n",
        "    # Nasal (back)\n",
        "    \"ng\": \"08_Nasal\",\n",
        "\n",
        "    # Lateral\n",
        "    \"l\": \"09_Lateral\",\n",
        "\n",
        "    # Semi-vowels (glides)\n",
        "    \"y\": \"10_Semi_Vowel\",\n",
        "\n",
        "    # Diphthongs and others (some overlapping)\n",
        "    \"ay\": \"03_Open_Mouth\",\n",
        "}\n",
        "\n",
        "# --- Helpers ---\n",
        "\n",
        "def get_phonemes_from_cmudict(word):\n",
        "    word = word.lower()\n",
        "    if word not in cmu_dict:\n",
        "        raise ValueError(f\"No phonemes found for word '{word}'\")\n",
        "    phonemes = cmu_dict[word][0]\n",
        "    return [p.lower().strip(\"0123456789\") for p in phonemes]\n",
        "\n",
        "def load_gan_model(viseme_class_path, epoch=100):\n",
        "    model_path = f\"{viseme_class_path}/generator_epoch_{epoch}.model.keras\"\n",
        "    return tf.keras.models.load_model(model_path)\n",
        "\n",
        "def generate_lip_frames(generator, latent_dim=100):\n",
        "    z = np.random.normal(0, 1, (1, latent_dim))\n",
        "    return generator.predict(z)\n",
        "\n",
        "def save_as_png(image_array, save_path):\n",
        "    image_array = np.clip(image_array, 0, 1)\n",
        "    image_array = (image_array * 255).astype(np.uint8)\n",
        "    img = Image.fromarray(image_array)\n",
        "    img.save(save_path)\n",
        "\n",
        "def create_gif_from_frames(folder_path, output_path=\"output.gif\", duration=500):\n",
        "    frame_files = sorted([f for f in os.listdir(folder_path) if f.endswith(\".png\")])\n",
        "    frames = [Image.open(os.path.join(folder_path, f)) for f in frame_files]\n",
        "\n",
        "    if frames:\n",
        "        frames[0].save(\n",
        "            output_path,\n",
        "            format=\"GIF\",\n",
        "            save_all=True,\n",
        "            append_images=frames[1:],\n",
        "            duration=duration,\n",
        "            loop=0\n",
        "        )\n",
        "        print(f\"✅ GIF saved to: {output_path}\")\n",
        "    else:\n",
        "        print(\"⚠️ No PNG files found to create GIF.\")\n",
        "\n",
        "def create_mp4_from_frames(folder_path, output_path=\"output.mp4\", fps=2):\n",
        "    frame_files = sorted([f for f in os.listdir(folder_path) if f.endswith(\".png\")])\n",
        "    if not frame_files:\n",
        "        print(\"⚠️ No PNG files found to create MP4.\")\n",
        "        return\n",
        "\n",
        "    first_frame = cv2.imread(os.path.join(folder_path, frame_files[0]))\n",
        "    height, width, _ = first_frame.shape\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    video = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    for file_name in frame_files:\n",
        "        frame = cv2.imread(os.path.join(folder_path, file_name))\n",
        "        video.write(frame)\n",
        "\n",
        "    video.release()\n",
        "    print(f\"✅ MP4 video saved to: {output_path}\")\n",
        "\n",
        "# --- Phoneme Duration Prediction ---\n",
        "\n",
        "def predict_phoneme_durations(phonemes, base_duration=0.1):\n",
        "    \"\"\"\n",
        "    Predict durations for each phoneme.\n",
        "    This is a simple rule-based predictor assigning a base duration to each phoneme.\n",
        "    \"\"\"\n",
        "    durations = []\n",
        "    for phoneme in phonemes:\n",
        "        # Assign longer duration to vowels\n",
        "        if phoneme in ['aa', 'ae', 'ah', 'eh', 'ih', 'iy', 'er', 'ey', 'uh', 'uw', 'aw', 'ow', 'oy', 'ay']:\n",
        "            durations.append(base_duration * 1.5)\n",
        "        else:\n",
        "            durations.append(base_duration)\n",
        "    return durations\n",
        "\n",
        "# --- Main generation logic ---\n",
        "\n",
        "def generate_from_word(word, base_model_dir, save_dir, fps=25):\n",
        "    phonemes = get_phonemes_from_cmudict(word)\n",
        "    print(f\"Phonemes: {phonemes}\")\n",
        "\n",
        "    durations = predict_phoneme_durations(phonemes)\n",
        "    print(f\"Predicted durations: {durations}\")\n",
        "\n",
        "    output_path = os.path.join(save_dir, word)\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "    frame_idx = 0\n",
        "\n",
        "    for phoneme, duration in zip(phonemes, durations):\n",
        "        viseme_class = phoneme_to_mouth_shape.get(phoneme)\n",
        "        if not viseme_class:\n",
        "            print(f\"Skipping unknown phoneme: {phoneme}\")\n",
        "            continue\n",
        "\n",
        "        generator_path = os.path.join(base_model_dir, viseme_class)\n",
        "        if not os.path.exists(generator_path):\n",
        "            print(f\"GAN model for {viseme_class} not found, skipping.\")\n",
        "            continue\n",
        "\n",
        "        generator = load_gan_model(generator_path)\n",
        "\n",
        "        # Calculate number of frames for this phoneme based on duration and fps\n",
        "        num_frames = max(1, int(duration * fps))\n",
        "\n",
        "        for _ in range(num_frames):\n",
        "            generated_clip = generate_lip_frames(generator)\n",
        "\n",
        "            if generated_clip.ndim == 5:\n",
        "                frame = generated_clip[0, 0]\n",
        "            elif generated_clip.ndim == 4:\n",
        "                frame = generated_clip[0]\n",
        "            else:\n",
        "                frame = generated_clip\n",
        "\n",
        "            save_path = os.path.join(output_path, f\"frame_{frame_idx:03d}.png\")\n",
        "            save_as_png(frame, save_path)\n",
        "            frame_idx += 1\n",
        "\n",
        "    print(f\"✅ PNG frames saved to: {output_path}\")\n",
        "\n",
        "    # Create GIF and MP4\n",
        "    gif_path = os.path.join(save_dir, f\"{word}.gif\")\n",
        "    mp4_path = os.path.join(save_dir, f\"{word}.mp4\")\n",
        "    create_gif_from_frames(output_path, gif_path, duration=int(1000 / fps))\n",
        "    create_mp4_from_frames(output_path, mp4_path, fps=fps)\n",
        "\n",
        "    return output_path\n",
        "\n",
        "# --- Run ---\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    word = input(\"Enter a word: \").strip()\n",
        "    base_model_dir = \"/content/drive/MyDrive/All_outputs/gans_allfolders\"\n",
        "    save_dir = \"/content/drive/MyDrive/All_outputs/mergeGANS\"\n",
        "    generate_from_word(word, base_model_dir, save_dir)\n"
      ],
      "metadata": {
        "id": "xOg0jszIZ41x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95f5b7e7-c07e-444f-8275-58b57d689b1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]   Package cmudict is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a word: map\n",
            "Phonemes: ['m', 'ae', 'p']\n",
            "Predicted durations: [0.1, 0.15000000000000002, 0.1]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "✅ PNG frames saved to: /content/drive/MyDrive/All_outputs/mergeGANS/map\n",
            "✅ GIF saved to: /content/drive/MyDrive/All_outputs/mergeGANS/map.gif\n",
            "✅ MP4 video saved to: /content/drive/MyDrive/All_outputs/mergeGANS/map.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# /content/drive/MyDrive/Dataset/Screenshot 2025-05-01 185610.png"
      ],
      "metadata": {
        "id": "NfB-rp7l_eB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator_epoch_100.model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "0jeK5V1FCPRa",
        "outputId": "14de3e79-268a-4a63-e197-95613bd3a92f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'generator_epoch_100' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-bfee4c383703>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerator_epoch_100\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'generator_epoch_100' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y3EIajnjNWos"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}